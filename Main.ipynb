{"cells":[{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"cf71a84290524611b1b980c77fc53b79","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"","block_group":"cf71a84290524611b1b980c77fc53b79"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"a4e0760e93054ea79e72d25d218eec00","deepnote_cell_type":"markdown"},"source":"# <center>Dictionary learning for classification problems</center>\n### <center> Industrial mathmatics project, TMA4320 Introduction to scientific calculations </center>\n#### <center> Duedate project: Monday Februay March 6th 2023 </center>\n#### <center> Group members: Eva Weiss, Paul Marino, Anja Ringstad </center>","block_group":"a4e0760e93054ea79e72d25d218eec00"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"3261c249-96d1-4d40-ad1f-1a70e51eae21","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"In this project we will make use of dictionary learning, and try to categorize the MNIST dataset. The MNIST dataset is a set of standardized pictures of drawn numbers, and is often used to test the accuracy and efficiency of a machine learning algorithm. Dictionary learning, as a subfield of machine learning, involves training programs to learn from and make predictions on data. It is a method which involves extracting a set of linear basis vectors from a dataset, and then using those basis vectors to represent the data more efficiently. One can then test how well a new datapoint can be described by a set of basis vectors. This can be used to classify that new datapoint. In this project we will make general code to create the basis vectors before creating specific bases for the MNIST dataset. Then test will be performed to evaluate the implementation of the dictionary learning method.","block_group":"3261c249-96d1-4d40-ad1f-1a70e51eae21"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"8bb6d8519c0841c49730e940acb3e7b3","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"1a)","block_group":"8bb6d8519c0841c49730e940acb3e7b3"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"9deee39c0b284218a37395abcbdcb117","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"Singular Value Decomposition (SVD) is a generalization of matrix diagonalization and a factorization technique. The goal of\r\nthe SVD is «decomposing the original matrix in terms of its singular values (Menke, 2012, s.127).» This is done by \r\ndecomposing any mxn matrix A into the product of three matrices:","block_group":"9deee39c0b284218a37395abcbdcb117"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"22bcd277-2fb8-40b1-bf74-6c259fa2f119","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"$$A = U\\Sigma V^T \\tag{1}$$","block_group":"22bcd277-2fb8-40b1-bf74-6c259fa2f119"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"50bc081c-8971-4cfe-bf5b-9bc719ca73e4","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"Where $U$ and $V^T$ are orthogonal matrices and $\\Sigma$ is diagonal and contains the singular values, or in this case eigenvalues, ordered from largest to \r\nsmallest. In dictionary learning we want to decompose A into a small amount of basis vectors. Eq (1) can be written as \r\n$$A=WH \\tag{2}$$\r\nwhere the dictionary with basis vectors $W=U$ and $H=\\Sigma V^T$.\r\n(Ludvigsen, 2023) ","block_group":"50bc081c-8971-4cfe-bf5b-9bc719ca73e4"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"2f2249fb680245a5ab4bd6806565f48e","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"The first task is to calculate the SVD compositions for matrix A1 using np.linalg.svd().  We can check if the function works by multiplying the matrices $U$, $\\Sigma$ and $V^T$ and seeing if it equals the original matrix $A$. ","block_group":"2f2249fb680245a5ab4bd6806565f48e"},{"cell_type":"code","metadata":{"tags":[],"cell_id":"dcc97a791891459fbe061f582d6ec916","source_hash":"eba39436","execution_start":1677966983723,"execution_millis":841,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"import numpy as np\nimport matplotlib.pyplot as plt","block_group":"dcc97a791891459fbe061f582d6ec916","execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"2523de5ab4614e148e2a7d2e7a6a6b3b","source_hash":"43bdd51","execution_start":1677966984573,"execution_millis":5,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"# Create matrices\nA1 = np.array([[1000,1],[0,1],[0,0]])\nA2 = np.array([[1,0,0],[1,0,0],[0,0,1]])\n\nb1 = np.array([2, 1, 0])   \nb2 = np.array([0, 0, 1])\nb3 = np.array([0, 1, 0])\n\nB =np.array([b1, b2, b3]).transpose()\n\n\n\n# Calculate SVD\nU,S,Vt = np.linalg.svd(A1, full_matrices = False)\n\n\nprint(\"Shape of S: \", S.shape)  # Expect (2,)\nprint(\"\\nU: \\n\", U)\nprint(\"\\nS: \\n\", S)\nprint(\"\\nVt: \\n\", Vt)\n\n#Check if SVD= A\nm = S.shape[0]\n\nprod1 = (U[:,:m]*S)@Vt          # Slicing U and using the hadamard product to avoid using S as a 2x2 matrix\nprint(f\"\\nUSVT = \\n{prod1}\")\n\n#Use np.allclose() to check if A and USVt are the same, while ignoring small rounding errors:\nprint(f\"\\nA1 and USVt equal?: {np.allclose(A1, prod1)}\") ","block_group":"2523de5ab4614e148e2a7d2e7a6a6b3b","execution_count":2,"outputs":[{"name":"stdout","text":"Shape of S:  (2,)\n\nU: \n [[ 1.e+00 -1.e-06]\n [ 1.e-06  1.e+00]\n [ 0.e+00  0.e+00]]\n\nS: \n [1.0000005e+03 9.9999950e-01]\n\nVt: \n [[ 0.9999995  0.001    ]\n [-0.001      0.9999995]]\nUSVT = \n[[ 1.00000000e+03  1.00000000e+00]\n [-2.18499053e-19  1.00000000e+00]\n [ 0.00000000e+00  0.00000000e+00]]\nA1 and USVt equal?: True\n","output_type":"stream"}]},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"188bf8c2c82f4f188150d5587fb57103","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"As we see from the output above, A1 and USVt are equal, or at least only differ by an extremely small amount caused by floating point errors. The floating point errors made it hard to compare the matrices A1 and USVt just by printing them, so the function np.allclose() was used to confirm if the matrices where the same.  Because the vector S only contains the diagonal elements without the zeros, the product USVt is not possible only using matrix multiplication because of S' dimensions. To avoid making S into a diagonal matrix, we used slicing and the dot product, which gets us to the same result. As the elements in S are sorted from largest to smallest, the first basis vector in U would be the most important for reconstructing A1. This means the weight of the first column would be greater than that of the second, and so on. As mentioned above, we want to represent A with only a few basis vectors in dictionary learning. The fact that some columns weigh more than others can therefore be used to represent A more efficiently.","block_group":"188bf8c2c82f4f188150d5587fb57103"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"03e4392df2e142c5a7ac75aa71da0479","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"1b)","block_group":"03e4392df2e142c5a7ac75aa71da0479"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"1e0b76b0fa81449c8ca5242719e6bb2e","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"By removing the least important parts of the SVD we get the reduced SVD. Removing the last m-d columns of U gives the reduced mxd matrix $U_d$. Similarly $V^T_d$ is obtained by removing the last n-d rows of the original matrix. ","block_group":"1e0b76b0fa81449c8ca5242719e6bb2e"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"2233386a149040fc96b6293eaf9d4996","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"This means that A can be fully reconstructed without using all the columns in U if A only has d non-zero values. The code below is made to confirm this.","block_group":"2233386a149040fc96b6293eaf9d4996"},{"cell_type":"code","metadata":{"tags":[],"cell_id":"eabd0ceebd8d4df6a3d4d36466267829","source_hash":"99bbe410","execution_start":1677966984594,"execution_millis":3,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"\nU_b,S_b,Vt_b = np.linalg.svd(A2, full_matrices = False)\n\nprint(\"U: \\n\", U_b)\nprint(\"S: \\n\", S_b)\nprint(\"Vt: \\n\", Vt_b)\nprint(\"S has a 0 as the last element, which makes the last column of U and the last row of Vt unncessary\")\n\n\nS_bd = np.trim_zeros(S_b)                # Removes elements = 0 in S\n\n\nprint(f\"\\nNew S (Sd) : \\n{S_bd}\")        # Confirm that elements = 0 are gone\n\nnb = S_bd.shape[0]                       # Find new n to slice U and Vt\n\n#Check if USdVt = A:\nprod2 = (U_b[:,:nb]*S_bd)@Vt_b[:nb, :]\nprint(f\"A1 and USdVt equal?: {np.allclose(A2, prod2)}\")\n","block_group":"eabd0ceebd8d4df6a3d4d36466267829","execution_count":3,"outputs":[{"name":"stdout","text":"U: \n [[-0.70710678  0.         -0.70710678]\n [-0.70710678  0.          0.70710678]\n [ 0.          1.          0.        ]]\nS: \n [1.41421356 1.         0.        ]\nVt: \n [[-1. -0. -0.]\n [ 0.  0.  1.]\n [ 0.  1.  0.]]\nS has a 0 as the last element, which makes the last column of U and the last row of Vt unncessary\n\nNew S (Sd) : \n[1.41421356 1.        ]\nA1 and USdVt equal?: True\n","output_type":"stream"}]},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"ba1b45d93d4d4a4e89bbd1cacde935d6","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"When finding the SVD of A2  and printing U, S and Vt it is revealed that the last element in S is zero. As the elemts in S essentially are the eigenvalues of A2, this means that we have a column in A2 which is linerarly dependent on the other columns. Also, if we multiply the three matrices it is obvious that the last column of U and the last row of Vt will not contain anything of importance for reconstructing A2. Therefore we could just slice away these parts of the matrices, and we can still reconstruct A2 with a smaller amount of basis vectors. For further tasks the function truncSVD, which slices the matrices to represent A without using all the basis vectors, is implemented below.  ","block_group":"ba1b45d93d4d4a4e89bbd1cacde935d6"},{"cell_type":"code","metadata":{"tags":[],"cell_id":"92c9541c26ea4b1182e11729c5240ada","source_hash":"cf3d8533","execution_start":1677966984594,"execution_millis":3,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"def truncSVD(U, S, Vt, d):\n    '''\n    Slices U,S,and Vt to avoid basisvectors with no information for the matrix= ASVt\n    ----------------------------------------\n    Input:\n    -U = m*n array with basis vectors\n    -S = 1d array with singular values\n    -Vt = array same first dimension as U\n    Ouput:\n    -W = sliced array U\n    -H = sliced array SVt\n    '''\n    # Slicing to delete unnecessary elemts:\n    Sd = S[:d]       \n    Ud = U[:,:d]\n    Vtd = Vt[:d, :]\n\n    W = Ud\n    H = (Vtd.T*Sd).T      # Using dot product to avoid making S into a diagonal matrix    \n    \n    return W, H\n\n","block_group":"92c9541c26ea4b1182e11729c5240ada","execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"27f38b0f9141443f9fedb34343bef77f","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"The function truncSVD() takes in U, S, Vt. It also takes in the amount of desired basis vectors, d. This makes it \r\neasy to delete unnecessary elements by slicing, as the elements in S are sorted. It returns W and H. The \r\ndictionary W is equal to Ud and the weights H are equal to SdVtd.","block_group":"27f38b0f9141443f9fedb34343bef77f"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"63e327450c83450282de69438850fa93","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"1c)","block_group":"63e327450c83450282de69438850fa93"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"20f457d187b2450eb9370bbbe52961d0","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"In order to find the distances between a matrix B and the dictionary W, the orthogonal projection of B onto W is needed. The function orthoproj() calculates the orthogonal projection using $P_W(b)=WW^Tb$. Then we find the columnwise distance from B to W with the function columndist() using np.linalg.norm() with the argument \"axis=0\". The calculations follow the equation $D_W(B) = [D_W(b_1) ... D_W(b_l]$","block_group":"20f457d187b2450eb9370bbbe52961d0"},{"cell_type":"code","metadata":{"tags":[],"cell_id":"90dd659ccf0242a6a24169b344fc248b","source_hash":"76400c92","execution_start":1677966984595,"execution_millis":4,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"def orthproj(W, B):\n    '''\n    Calculates the projection of a Matrix b onto a dictionary W\n    -----------------------------------------------------------\n    Input:\n    -W = dictionary with orthogonal columns\n    -B = matrix\n    Returns:\n    - projection of matrix b onto dictionary W\n    '''\n    WtB = W.T@B\n    proj = W@WtB\n\n    return proj\n\n\nW, H = truncSVD(U_b, S_b, Vt_b, 2)  #to find W_A2\n\n# Dictionaries from a) and b):\nW_A1 = U\nW_A2 = W\n\n# Projection of B onto dictionaries from a) and b)\nproj_A1 = orthproj(W_A1, B)\nproj_A2 = orthproj(W_A2, B)\n\nprint(f\"\\nProjection of B onto W_A1: \\n{proj_A1.round()}\")      # Using .round to make the matrix easier to look at (Avoid rounding errors)\nprint(f\"\\nProjection of B onto W_A2: \\n{proj_A2}\")\n\n\n\ndef columndist(W, B):\n    '''\n    Calculates the columnwise distances from B to W\n    -----------------------------------------------\n    Input:\n    -W = dictionary/matrix with orthogonal columns\n    -b = matrix\n    Output\n    - matrix with columnwise distance as elements\n    '''\n\n    dist = B-orthproj(W, B)\n    D = np.linalg.norm(dist, axis=0)        # Using axis = 0 to find the columnwise Frobeniusnorm\n    \n    return D\n\nprint(f\"\\nColumnwise distance B and W1: \\n{columndist(W_A1, B).round()}\")\nprint(f\"\\nColumnwise distance B and W2: \\n{columndist(W_A2, B)}\")\n    \n\n","block_group":"90dd659ccf0242a6a24169b344fc248b","execution_count":5,"outputs":[{"name":"stdout","text":"\nProjection of B onto W_A1: \n[[2. 0. 0.]\n [1. 0. 1.]\n [0. 0. 0.]]\n\nProjection of B onto W_A2: \n[[1.5 0.  0.5]\n [1.5 0.  0.5]\n [0.  1.  0. ]]\n\nColumnwise distance B and W1: \n[0. 1. 0.]\n\nColumnwise distance B and W2: \n[0.70710678 0.         0.70710678]\n","output_type":"stream"}]},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"30bdf9baace94e11972ac66e2d4afcf9","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"An import detail regarding the calculation of the orthogonal projection is that the product WtB is calculated first, and then W(WtB). This is because the mxm matrix WWt has a rank d<<m. Therefore it contains m-d vectors that are wasteful to calculate. By changing the order of computation one can avoid calculating and storing redundant vectors. The function columndist() is confirmed by calculating the columnwise distance between B and W1 and B and W2. ","block_group":"30bdf9baace94e11972ac66e2d4afcf9"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"53f8d3f6e0dd4125ae6c62d1361c1f57","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"1d)","block_group":"53f8d3f6e0dd4125ae6c62d1361c1f57"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"6810a182-ab97-4b08-831a-0f95ba2412f3","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"A different way of learning dictionaries is the Exemplar-based Non-Negative Matrix Factorization (ENMF). Non-Negative Matrix Factorization is used to decompose a non-negative matrix A(all elements larger or equal to zero):\r\n$$A \\approx W_+ H_+ \\tag{3}$$\r\nwhere W and H also are non-negative.\r\nThe ENMF approach is a a less computationally demanding way of making dictionaries. The dictionary $W_+$ is simply made by choosing columns at random from the matrix A. This means we don't have to do any training in contrast to the SVD approach, which is advantageous for larger datasets as calculating the SVD could take hours or even days. As we are going to use black and white images, the pixels are described using only positive values, and thus we can use the ENMF approach. \r\nThe function nnproj() calculates the non-negative projection:","block_group":"6810a182-ab97-4b08-831a-0f95ba2412f3"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"3f806c89-d7f6-43ad-90eb-6f8fe7c8a735","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"$$ P^{+}_{W_+}(A)=W_+H^* \\tag{4}$$","block_group":"3f806c89-d7f6-43ad-90eb-6f8fe7c8a735"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"ec520ab4-a152-4fcc-860c-06e8b2ad38f8","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"where $H^*$ is given by","block_group":"ec520ab4-a152-4fcc-860c-06e8b2ad38f8"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"d5e47739-ce17-46bb-b60b-2613d5c6cd35","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"$$H^* = \\text{arg min}_{H_+ \\in \\mathbb{R}^{dxn}} \\| A_+ - W_+H_+\\|^2_F \\tag{5}$$","block_group":"d5e47739-ce17-46bb-b60b-2613d5c6cd35"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"f0542cb8-00c6-4790-8cdb-b99ef1ed3ad5","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"The solution of Eq (5) has to be found numerically, for example by using the algorithm","block_group":"f0542cb8-00c6-4790-8cdb-b99ef1ed3ad5"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"95750407-0d2b-4cb9-a577-0c1399643cdd","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"$$H_{k+1}=H_k\\odot (W_+^TA)\\oslash(W^T_+W_+H_k+\\delta) \\tag{6}$$","block_group":"95750407-0d2b-4cb9-a577-0c1399643cdd"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"70a5e053-97d0-4095-97bb-f4754c6a8679","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"where $\\delta$ is the safe divsion factor that prevents division by zero (Ludvigsen, 2023).\r\nWe chose to implement a new function, nncolumndist(), to find the non-negative columndist between $W_+$ and a matrix $B$.","block_group":"70a5e053-97d0-4095-97bb-f4754c6a8679"},{"cell_type":"code","metadata":{"tags":[],"cell_id":"f3e98200891c4f09ba24d05a060f6619","source_hash":"b4de931d","execution_start":1677966984600,"execution_millis":18,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"def nnproj(W_nn, B, maxiter, delta):\n    '''\n    calculates the non-negative projection as shown in equation\n    -----------------------------------------------------------\n    Input:\n    -W_nn    = non-negative dictionary with orthogonal columns\n    -B       = matrix\n    -maxiter = Max iterations to find H*\n    -delta   = safe-division factor\n    Output:\n    matrix, non-negative projection of B onto the positive dictionary W_nn\n    '''\n    # Find dimensions n and d for H-matrix\n    m,n = B.shape\n    m,d = W_nn.shape\n    \n    H = np.random.uniform(0, 1, size= (d, n))\n    \n    WtB = (W_nn.T)@B\n    WtW = (W_nn.T)@W_nn\n    \n    # Calculate H*\n    for i in range(maxiter):\n        H = H*(WtB)/(WtW@H+delta) \n    \n    proj = W_nn@H\n    \n    return proj\n\n\ndef nncolumndist(W, B, maxiter, delta):\n    '''\n    Calculates the columnwise distances from B to the non-negative dictionary W\n    -----------------------------------------------\n    Input:\n    -W       = non-negative dictionary with orthogonal columns\n    -B       = matrix\n    -maxiter = Max iterations to find H*\n    -delta   = safe-division factor\n    Output\n    - matrix with columnwise distance as elements\n    '''\n\n    dist = B-nnproj(W, B, maxiter, delta)\n    D = np.linalg.norm(dist, axis=0)        # Using axis = 0 to find the columnwise Frobeniusnorm\n    \n    return D\n\n\n\nmaxiter = 50\ndelta = 10**(-2)\n\n# Calculate non-negative projection of B onto A1 and A2\nprojA1 = nnproj(A1, B, maxiter, delta )\nprojA2 = nnproj(A2, B, maxiter, delta)\n\nprint(f\"\\nnon-negative proj A1 : \\n{projA1}\")\nprint(f\"\\nnon-negative proj A2 : \\n{projA2}\")\n\n# Calculate columnvise distance from B to A1 and A2 using the non-negative projection\nD_A1_B = nncolumndist(A1, B, maxiter, delta)\nD_A2_B = nncolumndist(A2, B, maxiter, delta)\n\nprint(f\"\\ndistance A1 and B:\\n\", D_A1_B) \nprint(f\"\\ndistance A2 and B:\\n\", D_A2_B)","block_group":"f3e98200891c4f09ba24d05a060f6619","execution_count":6,"outputs":[{"name":"stdout","text":"\nnon-negative proj A1 : \n[[2.00164469 0.         0.495     ]\n [0.98664334 0.         0.495     ]\n [0.         0.         0.        ]]\n\nnon-negative proj A2 : \n[[1.495 0.    0.495]\n [1.495 0.    0.495]\n [0.    0.99  0.   ]]\n\ndistance A1 and B:\n [0.01081682 1.         0.70714214]\n\ndistance A2 and B:\n [0.70714214 0.01       0.70714214]\n","output_type":"stream"}]},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"c615cac2efd34406b67c0c38079d5987","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"As in 1c), it is important to choose an effective way of finding the projection in order to avoid unnecessary storing or calculation of data. Since we need a for loop to estimate $H^*$ all constants during the iterations, as $W^TB$ and $W^TW$, are calculated oustide the loop. The printed results above show that our calculations agree with the given answer: $D_{A1}(B) \\approx [ 0, 1, \\frac{1}{\\sqrt{2}} ]$. As expected the numerical error is quite large in comparison to 1c).  This is beacuse we find $H^*$ numerically and only use 50 iterations. By using more iterations the error would become smaller, but we will continue to use $maxiter=50$ throughout this project as given in the project description.  ","block_group":"c615cac2efd34406b67c0c38079d5987"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"6644e581bea54295bc0fc1d90a9a654a","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"2a) ","block_group":"6644e581bea54295bc0fc1d90a9a654a"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"405fe891-677b-41d3-8cda-781bbe1bc3a0","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"The general purpose of task two is to construct and train dictionaries from real data, in this case data from the MNIST dataset. Each image in the dataset has 28x28 pixels and has been normalized so that the background is black while the digit itself is white (Ludvigsen, 2023). The training dataset provided for this project contains 5000 images of each of the integers in the range [0,9]. The dictionaries constructed in task two will however all be trained on the digit three. In this part of the task, the first 16 images from the training dataset of this digit will be plotted. By doing so one gets a general idea of how the handwritten digits look, and to which degree the individual digits differ from each other. This is useful to give an insight to the foundation of data which will be used to train the dictionaries. ","block_group":"405fe891-677b-41d3-8cda-781bbe1bc3a0"},{"cell_type":"code","metadata":{"tags":[],"cell_id":"6ee681f1cfeb4dc88f7e0d8a953e20fa","source_hash":"4244bd1e","execution_start":1677966984616,"execution_millis":979,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"# Loading the data and rescaling \ntrain = np.load('train.npy')/255.0\ntest = np.load('test.npy')/255.0\n\n# Shapes are (number of pixels, number of classes, number of data)\nprint(train.shape) # Should be (784,10,5000)\nprint(test.shape)  # Should be (784,10,800)","block_group":"6ee681f1cfeb4dc88f7e0d8a953e20fa","execution_count":7,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'train.npy'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn [7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Loading the data and rescaling \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255.0\u001b[39m\n\u001b[1;32m      3\u001b[0m test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255.0\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Shapes are (number of pixels, number of classes, number of data)\u001b[39;00m\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/numpy/lib/npyio.py:390\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    388\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    391\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.npy'"]}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"29e61c1ec89749dab8084ff2c1b5b968","source_hash":"6bdaf65d","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"def plotimgs(imgs, nplot = 4):\n    \n    '''\n    Plots the nplot*nplot first images in imgs on an nplot x nplot grid. \n    Assumes heigth = width, and that the images are stored columnwise. \n    --------------------------------------------------------------------\n    Input:\n    - imgs: (height*width,N) array containing images, where N > nplot**2\n    - nplot: integer, nplot**2 images will be plotted\n    \n    '''\n\n    n = imgs.shape[1]\n    m = int(np.sqrt(imgs.shape[0]))\n\n    #assert(n > nplot**2), \"Need amount of data in matrix N > nplot**2\"\n\n    # Initialize subplots\n    fig, axes = plt.subplots(nplot,nplot,figsize=(10,10))\n\n    # Set background color\n    plt.gcf().set_facecolor(\"lightgray\")\n\n    # Iterate over images\n    for idx in range(nplot**2):\n\n        # Break if we go out of bounds of the array\n        if idx >= n:\n            break\n\n        # Indices\n        i = idx//nplot; j = idx%nplot\n\n        # Remove axis\n        axes[i,j].axis('off')\n\n        axes[i,j].imshow(imgs[:,idx].reshape((m,m)), cmap = \"gray\")\n    \n    # Plot\n\n    fig.tight_layout()\n    plt.show()\n","block_group":"29e61c1ec89749dab8084ff2c1b5b968","execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"ae11f4add63a4509a3b89aa2f2b9a55d","source_hash":"fec3533c","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"# Plotting the first 16 images of the integer three \nprint(\"First 16 images of the integer 3 in the MNIST-dataset\")\nplotimgs(train[:,3,:], nplot = 4)","block_group":"ae11f4add63a4509a3b89aa2f2b9a55d","execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"f9c628b18ee44da5be528e37a9c2985b","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"2b) ","block_group":"f9c628b18ee44da5be528e37a9c2985b"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"6dbb48fb7d1e420ca7fcf0ada8f1c36d","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"In this project two approaches to creating dictionaries for the chosen digit will be implemented, firstly the SVD method. The first step in this process is to calculate the full SVD for a matrix A, which contains a training dataset of a thousand images of the chosen digit stored columnwise. Since this calculation is a computationally demanding task, it will only be done once throughout task two. Using the results from this calculation, the truncated SVD using d = 16 (number of desired basis vectors) will be calculated to remove redundant vectors, and in turn creating a dictionary. To get a visual impression of the dictionary, the images of the basis vectors will be plotted, and how well these capture the features of the dataset will be evaluated. Lastly the singular values of matrix A will be plotted from highest to lowest value.","block_group":"6dbb48fb7d1e420ca7fcf0ada8f1c36d"},{"cell_type":"code","metadata":{"tags":[],"cell_id":"6f7fb8cec15c40c481b9bcaf82e60827","source_hash":"d1e19947","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"def attainData(imgs, n_data): \n    \n    '''\n       Attains n_test datapoints of an single interger x. \n       --------------------------------------------------\n       Input: \n       - imgs = datapoints for class/integer x from file 'train.npy'\n       - n_data = number of datapoints \n       \n       Output: \n       - A = matrix containing n_test datapoints stored columnwise \n    '''\n    \n    n = imgs.shape[1]                         # Number of datapoints in each class \n    assert(n > n_data)                        # Cheking there is enough available data in class\n    \n    m = imgs.shape[0]                         # Number of pixels \n    A = np.zeros((n_data, m))                 # Empty 2d-array to store dataset of size (n_data, m) \n    \n\n    for i in range(n_data):                   # Attaining n_data datapoints from file train.npy \n        A[i] = np.array(imgs[:,i])\n        \n    A = np.transpose(A)                       # Storing datapoints columnwise \n     \n    return A                                  # Returning matrix containing n_data datapoints \n\n","block_group":"6f7fb8cec15c40c481b9bcaf82e60827","execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"9ae59a50ccd34187b0ff706019808431","source_hash":"fe0424bd","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"n_train = 1000                                # Size of training dataset\nA_train = attainData(train[:,3,:], n_train)   # Matrix with datapoints stored columnwise\n\n\nU_train,S_train,Vt_train = np.linalg.svd(A_train, full_matrices = False)  # Calculating the full SVD for matrix A_train\n\nW_train, H_train, Sd_train = truncSVD(U_train, S_train, Vt_train, 16)     # Calculating the truncated SVD\n\n\nprint(\"Plot of d = 16 left singular vectors\")                             # Plotting d = 16 left singular vectors \nplotimgs(W_train, nplot = 4)","block_group":"9ae59a50ccd34187b0ff706019808431","execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"6cc509f49083487ead16e951578c9d16","source_hash":"766c58c0","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"xvals = np.arange(1,17)                                    # x-values for plotting singular values                 \n\n# Plotting the singular values from highest to lowest \nplt.figure(figsize = (9,7))\nplt.semilogy(xvals, S_train, label = \"Singular values\")    # Using logarithmic y-axis \n\n# Formating plot \nplt.tick_params(top= False, bottom=True, left=True, right=True, labelleft=True, labelbottom=True)\nplt.title(\"Singular values from highest to lowest\")\nplt.ylabel(\" Singular value, logarithmic scale\")\nplt.grid(ls =\"-.\")\nplt.legend()\nplt.show()\n","block_group":"6cc509f49083487ead16e951578c9d16","execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"4d2a557d74034164865aed55ff0354d4","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"Because the basis vectors in W can be seen as eigenvectors of A, they are stored in W from most to least important to reconstruct the original matrix. Since the plot shows the first 16 vectors in W, the images showcase the most important features needed to represent an image of the chosen digit. In general, the individual basis vectors mostly capture the placements of the important curvatures (the very light areas) of the chosen digit. The orientation of the basis vectors is in general upright and not slanted, and by just looking at the four first images it is intuitive that layering these images on top of each other will create a rough representation of the integer three comparable to the images in the original dataset. In this context it is also evident that the level of detail increases as the number of vectors used in the representation increases. It is therefore fair to conclude that the basis vectors capture the most important features of the digit the dictionary is trained on. ","block_group":"4d2a557d74034164865aed55ff0354d4"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"74cd6ffa109944dfad016f27bdde092b","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"The plot of the singular values to the matrix A, shows the matrix has a little over 500 nonzero singular values, which corresponds to an approximate rank of about 500. As the singular values can be considered as eigenvalues of matrix A, and the basis vectors in W as corresponding eigenvectors, the graph essentially shows the reasoning behind the reduced SVD method. The basis vectors with corresponding zero singular value are linearly dependent, and therefore do not represent new information for the reconstruction, which is why removing them when calculating the reduced SVD doesn’t affect the dictionary’s ability to recreate the original image. ","block_group":"74cd6ffa109944dfad016f27bdde092b"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"1fb265ffeae4408cbe3143636ed41a03","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"2c) ","block_group":"1fb265ffeae4408cbe3143636ed41a03"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"80787b82-8984-4cad-8c62-82c1ffbd5e96","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"By choosing an arbitrary image from the dataset in matrix A and projecting it orthogonally on to the dictionary W = Ud, the dictionary’s qualitative capabilities in recreating the image´s most important features can be evaluated. This is repeated for dictionaries containing varying number of basis vectors, respectively d = 16, 32, 64, 128. The qualitative relationship between the number of basis vectors and the dictionary’s ability to represent an image can be observed by plotting the representation beside the original image. ","block_group":"80787b82-8984-4cad-8c62-82c1ffbd5e96"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"bc7a3a09-d7e9-4ce4-9917-a89d42653b71","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"To make a machine learning model that can identify images of digits with high accuracy, it is also of interest to consider how well the dictionary can represent digits that it is not trained on. The reasoning behind this is that a dictionary that can represent other digits too well is problematic for classification. Therefore, the same experiment as for the image from the dictionaries training dataset, will be conducted for an image of the digit six. ","block_group":"bc7a3a09-d7e9-4ce4-9917-a89d42653b71"},{"cell_type":"code","metadata":{"tags":[],"cell_id":"d4f46ffc7028453e90eba09e1899cf79","source_hash":"dc70390f","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"def imageProjectionComp(b, d, U, S, Vt, name):\n    \n    '''\n       Calculates the truncated SVD for value of d. Thereafter the projection of the image b on to \n       the obtained basis Ud is calculated. Lastly the projection is  ploted next to the original\n       image for comparison. \n       --------------------------------------------------------------------------------------------\n       Input: \n       - b = original image from dataset \n       - d = number of singular vectors\n       - U = m*n array with basis vectors\n       - S = 1d array with singular values\n       - Vt = array same first dimension as U\n    \n    '''\n    \n    \n    W, H, Sd = truncSVD(U, S, Vt, d)   # Calculating truncated SVD for d\n    proj = orthproj(W, b)              # Calculating orthogonal projection\n    \n    \n    m = int(np.sqrt(b.shape))          # Reshaping data for plotting \n    b = b.reshape((m,m))\n    \n    n = int(np.sqrt(proj.shape))       # Reshaping data for plotting \n    proj = proj.reshape((n,n))\n    \n    \n\n    \n    # Making plot to compare original image with projection \n   \n    fig, axes = plt.subplots(1,2,figsize=(10, 10))              # Initialize subplots\n    #plt.gcf().set_facecolor(\"lightgray\")                       # Set background color\n    \n    \n    axes[0].imshow(b, cmap = \"gray\")                            # Ploting original image \n    axes[0].set_title(f\"Original image {name} \", )\n    axes[0].axis('off')\n     \n    name = name.replace(\"$\", \"\")\n    \n    axes[1].imshow(proj, cmap = \"gray\")                         # Ploting projection \n    axes[1].set_title(f\"$P_w({name})$\\nd={d}\")\n    axes[1].axis('off')\n    ","block_group":"d4f46ffc7028453e90eba09e1899cf79","execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"7df401bf995c4b35950f3266bdb9428f","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"","block_group":"7df401bf995c4b35950f3266bdb9428f"},{"cell_type":"code","metadata":{"tags":[],"cell_id":"137f5c316a894b7ba5a0dc614aa2a85d","source_hash":"81bb10f1","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"b = A_train[:,0]             # Singel image in desiered dataset (3)\n\nd_vals = [16, 32, 64, 128]   # Array with different values for the number of singular vectors when \n                             # calculating the turncated SVD \n\n\nfor i in d_vals:                                              # Calulating projection of b and plotting comparison\n    imageProjectionComp(b, i, U_train,S_train,Vt_train, \"b\")  # of projection and original image for different values \n                                                              # of d using function 'imageProjectionComp'\n","block_group":"137f5c316a894b7ba5a0dc614aa2a85d","execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"f67b9de46c564634a132a58cf32b4651","source_hash":"7cd7f744","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"A_th = attainData(train[:,6,:], n_train)    # Attaining matrix with datapoints from different class (6)\nb_th = A_th[:,0]                            # Singel Image of the integer six \n\n\nfor i in d_vals:                                                            # Calulating projection of b_th and plotting comparison\n    imageProjectionComp(b_th, i, U_train, S_train, Vt_train, \"$\\hat{b}$\")   # of projection and original image for different values \n                                                                            # of d using function 'imageProjectionComp'\n        ","block_group":"f67b9de46c564634a132a58cf32b4651","execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"17d24ba521fe480dbefc8c7ce9172260","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"In general, the dictionary manages to capture the general shape of the digit, independent of the number of basis vectors. However, one can observe that as the number of basis vectors in the dictionary W increases, the dictionary’s ability to accurately represent the details in the original image also improves. This improvement in representation is most noticeable when it comes to the sharpness of the digits outline. The projections that have been done onto dictionaries with a lower number of basis vectors, are more blurred and have softer edges. This makes sense as there are fewer available basis vectors to utilize in the linear combination, and therefore some details of the image is lost. Common to all the representations is the presence of ghosting (black pixels around the outline of the digit), which does not improve with increasing number of basis vectors. The ghosting occurs because the SVD approach allows negative pixel values. When plotting an image, the darkest pixel (which is black) is set to the lowest pixel value, which will be a negative value  with the SVD approach. This leads to a lighter background because the background has pixel value zero, and because there needs to be space in the value scale for the negative pixel values, zero no longer gets the darkest pixel. ","block_group":"17d24ba521fe480dbefc8c7ce9172260"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"cd1b779b-5ad6-403d-a5e2-eb08d013fd2b","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"When using an image that W is not trained on, the plots in general show little to no resemblance to the original image, especially when there are few basis vectors in the dictionary. The representation nevertheless to some extent improves with an increasing number of basis vectors as observed previously. In common for all the representations is that the contrast is lower than in the original image, which indicates that there are negative pixel values. The “digits” themselves resemble more of a blob than an actual digit, although one can make out the original digit from the projection onto the dictionary with 128 basis vectors. This representation is poor and characterized by a lot of ghosting, but catches the general shape. ","block_group":"cd1b779b-5ad6-403d-a5e2-eb08d013fd2b"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"8cf46bd795234635940a3d6808f6db18","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"2d) ","block_group":"8cf46bd795234635940a3d6808f6db18"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"ab3598bb004e429990112b085103a8ea","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"To quantitatively consider what happens when d increases, *expression* for dictionaries with d ∈ [1, 784] will be calculated for both the training dataset in matrix A, and a matrix containing a dataset of the same size with images of the digit six. The grid for the d values utilized have a step size of 16, and the distance *expression* will be plotted as a function of d using a logarithmic y-axis. ","block_group":"ab3598bb004e429990112b085103a8ea"},{"cell_type":"code","metadata":{"tags":[],"cell_id":"c4c34657efae478b8b5e5569a87080c1","source_hash":"77c7873e","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"from scipy import linalg as LA \n\nd_grid = np.linspace(1, 784, 49, dtype = int)   # Array with 49 d values in the range [1, 784] with step 16 \n\n\ndist_train = np.zeros(len(d_grid))              # Empty arrays to hold calculated distances \ndist_th = np.zeros(len(d_grid))\n\n\nfor i in range(0, len(d_grid)):           \n    \n    W, H, Sd = truncSVD(U_train, S_train, Vt_train, d_grid[i])    # Calculating truncated SVD\n                                  \n    # Calculating distance from \n    dist_train[i] = LA.norm(columndist(W, A_train))               # Dataset W is trained on \n    dist_th[i] = LA.norm(columndist(W, A_th))                     # Dataset W is not trained on \n\n    \n# Plotting distance as function of d \nplt.figure(figsize = (9,7))\nplt.semilogy(d_grid, dist_train, label = \"Trained\")        # Trained \nplt.semilogy(d_grid, dist_th, label = \"Untrained\")         # Untrained \n\n# Formating plot \nplt.title(f\"$|| A - P_w(A) ||^2_f$ as function of the number of basis vectors\\nSVD approach\")\nplt.xlabel(\"Number of basis vectors d\")\nplt.ylabel(\"$|| A - P_w(A) ||^2_f$\")\nplt.grid(ls = \"-.\")\nplt.legend()\nplt.show()","block_group":"c4c34657efae478b8b5e5569a87080c1","execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"e89b3ff821e74278ab1a2ad0813cf88b","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"The graph above shows that as the number of basis vectors in the dictionary increases, the distance from matrix A and its projection onto the linear space spanned by the dictionary decreases. This distance eventually reaches zero when the number of basis vectors becomes sufficiently large. Zero distance between the original matrix and its projection indicates that the dictionary can perfectly recreate the original matrix, and in this case a little over 500 basis vectors are needed for this level of accuracy. Since the basis vectors are stored from most to least important for image representation, this implies that the rest of the basis vectors carry redundant information or at least not any new useful information. This graph resembles the graph in 2b) of the singular value to the matrix A.","block_group":"e89b3ff821e74278ab1a2ad0813cf88b"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"52a9c1ec-bae7-415f-9fc3-f86c7a269948","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"One can observe that the distance between the original image of the digit six and its projection in the linear space spanned by W is consistently larger than for the image of the digit the dictionary is trained on. The difference in distance for the two images increases as the number of basis vectors increase. This implies that each basis vector doesn’t contribute as much information in the representation of the digit six´s image. A consequence of this is that the number of vectors that carry information important to recreate the original image is larger, and therefore the distance is larger for a bigger amount of basis vectors. This relationship is the most important observation in this context, as this property is crucial for classification. The algorithm used to classify digits later, scores the image based on the distance to its projection on to the respective dictionaries for digits in the range [0,9]. It then classifies the image as the digit with the shortest distance to the corresponding dictionary. The dictionaries’ poor ability to represent digits that it is not trained on is therefore favourable.","block_group":"52a9c1ec-bae7-415f-9fc3-f86c7a269948"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"a299cfd31ca44ac6b519a377a8aee2f6","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"2e) ","block_group":"a299cfd31ca44ac6b519a377a8aee2f6"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"38b24152634e4f09a1445965ad1952a5","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"Previously in this task the dictionaries have been created using the SVD approach, but there are multiple possible algorithms to construct dictionaries. In this part of task two the ENMF approach described in 1d) will be implemented for d = 32. To qualitatively compare the SVD and the ENMF approach, their ability to represent images in the training dataset will be considered by plotting a selection of the projections of the images in matrix A on to both dictionaries.","block_group":"38b24152634e4f09a1445965ad1952a5"},{"cell_type":"code","metadata":{"tags":[],"cell_id":"c11f0f28c0c24671aa1ca56c96e1c22a","source_hash":"78ad79e5","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"def Wnn(A, d): \n    \n    '''\n       Attains the non negative matrix W+ containing a basis, where the basis vector \n       are randomly selected columns of the matrix A \n       ------------------------------------------------------------------------------\n       Input: \n       A = matrix containing n_test datapoints stored columnwise \n       d = number of basis vectors\n       \n       Output: \n       Wnn = matrix with d basis vectors selected at random from matrix A \n    '''\n    \n    randomIndex = np.random.choice(A.shape[1], d, replace=False)    # Replace = False to ensure that no index is selected \n                                                                    # multiple times \n          \n    Wnn = np.zeros((len(randomIndex), A.shape[0]))          \n    \n    for i in range(len(randomIndex)):                               # Storing the random columns of A in Wnn\n         Wnn[i] = np.array(A[:,i])\n     \n    Wnn = np.transpose(Wnn)                                         # Transposing to store columnwise \n     \n    return Wnn   \n","block_group":"c11f0f28c0c24671aa1ca56c96e1c22a","execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"34c9e213cfb64618a39e8cca590021c0","source_hash":"f3a1f68d","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"Wnn_32 = Wnn(A_train, 1000)   # W+ basis with 32 basis vectors \n\n\nmaxiter = 50                  # Maximum number of iterations \ndelta = 10**-10               # Safe-division factor\n\n\nNonNegProj = nnproj(Wnn_32, A_train, maxiter, delta)          # Calculating non-negative projection of A on to linear space \n                                                              # spaned by W+\n\n\n# Checking that the projection is not equal to original dataset to verfiy projection \nassert(np.array_equal(NonNegProj, A_train) == False) \n\n\nW_32, H_32, Sd_32 = truncSVD(U_train, S_train, Vt_train, 32)  # Calculating truncated SVD for d = 32 \nSVDproj = orthproj(W_32, A_train)                             # Calculating orthogonal projection onto W \n\n\n\n# Plotting 16 first projections of A_train on to the linear space spaned by 32 basis vectors  \n\nprint(\"ENMF approach:\")             # Basis derived with ENMF approach \nplotimgs(NonNegProj, nplot = 4)\n\n\nprint(\"SVD approach:\")              # Basis derived with SVD approach \nplotimgs(SVDproj, nplot = 4)\n","block_group":"34c9e213cfb64618a39e8cca590021c0","execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"e2166626a8a743eba2d1c354fada3f11","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"The first of the two plots above show the non-negative projections onto the dictionary constructed using the ENMF approach. This plot shows an image representation which is considerably closer to the original images than the representation made with the dictionary trained using the SVD approach. For the ENMF approach the images' contrast is better preserved and the background is not characterized by ghosting. When it comes to the digits themselves, the projection captures the general shape well, and the outlines have little blurriness. Since the ENMF approach assumes that the images are non-negative, the darkest pixels in the images will always have value zero, which corresponds to the background’s pixel value. ","block_group":"e2166626a8a743eba2d1c354fada3f11"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"01e77a8a-d5be-4dd4-8794-954249287c5f","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"The ENMF representation was perceived so well that it was initially questioned if the plot shows projections, and not original images, unlike for the projections made onto the dictionary made with the SVD approach, where the representation of the digits in general has blurred lines and a weaker colour contrast. However the general shape of the digits is well captured by the dictionary, but with a lower level of detail compared to the ENMF approach. By comparison it is evident that the non-negative projection onto the ENMF dictionary is superior in visually representing the original images. The reason for this is that the non-negative pixel values of the original images are considered in the ENMF approach. ","block_group":"01e77a8a-d5be-4dd4-8794-954249287c5f"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"e72bb561a7494dc7a2c191038d4eb7a8","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"2f) ","block_group":"e72bb561a7494dc7a2c191038d4eb7a8"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"9cc2aff6-accc-4a07-a57d-062876c725d7","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"With the SVD approach it was observed that as the number of basis vectors increased, the distance between the projection and the sub-space spanned by the dictionary decreased, and eventually reached approximately zero. In this part of task two this quantitative relationship will be considered for d ∈ [1, 1000] with respect to the ENMF approach. The d grid values that will be utilized have a coarse step size. The results will be plotted using logarithmic y-axis. ","block_group":"9cc2aff6-accc-4a07-a57d-062876c725d7"},{"cell_type":"code","metadata":{"tags":[],"cell_id":"b9b4bc77db98456b93c90f52ce5cb199","source_hash":"580d378a","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"def diffNumDist(num, d_vals):\n    \n    '''\n       Attains dataset of the integer num, and calculates distance from the dataset to projection of dataset \n        in the linear space spanned by W+ for differt number of basis vectors. \n       -----------------------------------------------------------------------------------------------------\n       Input:\n       - num = interger between 0-9\n       - d_vals = array with d values in the range [0, 1000]\n       \n       Output: \n       - dist = array with distance from dataset to projection of dataset in the linear space spanned by W for \n                varing number of basis vectors d \n       \n    '''\n    \n    dataset = attainData(train[:, num, :], n_train)   # Dataset containing 1000 datapoints of integer num\n    dist = np.zeros(len(d_vals))                      # Empty array to hold distances  \n    \n    for i in range(0 , len(d_vals)): \n        Wplus = Wnn(A_train, d_vals[i])               # Obtaining W+ with d basis vectors \n        \n        dist[i] = LA.norm(nncolumndist(Wplus, dataset, maxiter, delta)) # Calculating distance fromm dataset to \n                                                                        # projection in linear space spaned by W+\n    \n    return dist \n","block_group":"b9b4bc77db98456b93c90f52ce5cb199","execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"7f8a8a15d6674d04afa4ede714f08720","source_hash":"7c969fd8","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"ENMF_d = np.logspace(1,3,10, dtype = np.int64)\nnums = [3, 4, 8, 1, 5]                   \ndistances = np.zeros((6, len(ENMF_d)))  \n\nfor i in range(0, len(nums)): \n    distances[i] = diffNumDist(nums[i], ENMF_d)                 # Calulating distance from datasets containing \n                                                                # datapoints for differnt integers to linear \n                                                                # space spanned by W+\n\n# Plotting results \nplt.figure(figsize = (9,7))                                                         \nfor j in range(0, len(nums)): \n    if j == 0: \n        plt.semilogy(ENMF_d, distances[j], label = \"Trained (3)\")              # Integer W+ is trained on \n    else: \n        plt.semilogy(ENMF_d, distances[j], label = f\"Untrained ({nums[j]})\")   # Integers W+ is not trained on \n        \n# Formating plot \nplt.xlabel(\"Number of basis vectors d\") \nplt.ylabel(\"$|| A - P_{w+}^+(A) ||^2_f$\")\nplt.title(\"$|| A - P_{w+}^+(A) ||^2_f$ as a function of the number of basis vectors\")\nplt.grid(ls = \"-.\")\nplt.legend()\nplt.show()  \n\n\nplt.figure(figsize = (9,7))\nplt.semilogy(d_grid, dist_train, label = \"SVD,Trained\") \nplt.semilogy(ENMF_d, distances[0], label = \"ENMF, Trained\")\nplt.legend()\nplt.ylabel(\"$|| A - P_{w+}^+(A) ||^2_f$\")\nplt.title(\"$|| A - P_{w+}^+(A) ||^2_f$ as a function of the number of basis vectors\\nSVD and ENMF approach\")\nplt.grid(ls = \"-.\")\nplt.show()","block_group":"7f8a8a15d6674d04afa4ede714f08720","execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"e9e3202d844243b4aa372738b81cc1a8","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"As for the SVD approach, the distance between the image and the projection of the image onto the dictionary decreases as the number of basis vectors increase. However, the distance is consistently much larger both for the image from the training dataset and the image of another digit, compared to the case with the SVD dictionary. The large distance is however most likely due to numerical error of the projection method, as many iterations are needed for it to converge. The most important trait is however that despite the numerical error in the projection method, the distance is always smallest for the digit which the dictionary is trained on. The randomness does not seem to effect our results very much, as we get about the same graph even though we use a new Wnn each time.","block_group":"e9e3202d844243b4aa372738b81cc1a8"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"8dd7aa67127648ce917687fccb8cfddc","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"3a","block_group":"8dd7aa67127648ce917687fccb8cfddc"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"f15dc46b-3b71-4cd4-8a61-b39576619444","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"In part three of this project we will be attempting to classify a set of test data, and then see how well the model performs. The data points will be scored with the distance to the basises, and then classified according to this score. The data point will be classified as the class with the lowest score. It is also relevant to find the most likely member of a class, in this case a one, and compare it to a misclassified one. The effect of the variable d on accuracy will also be tested and discussed in this part of the project.","block_group":"f15dc46b-3b71-4cd4-8a61-b39576619444"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"0cc85e6b-1a1b-4915-b8bc-3762b2e89f4d","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"The code below makes predictions for a set of data with a given set of dictionaries. The function  predict() is for the SVD method, and predictNN() for the ENMF method. The SVD function also finds the most likely image of a one, the one with the smallest distance to the ones basis.","block_group":"0cc85e6b-1a1b-4915-b8bc-3762b2e89f4d"},{"cell_type":"code","metadata":{"tags":[],"cell_id":"58199cd2a15a4d3d8a96c8430befcc09","source_hash":"86e30ae6","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"def predict(B, Ws, digits):\n    '''\n    This function takes in a set of test data, a set of \n    dictionaries for all digits, and a set of which digits are in the test data.\n    ----------------------------------\n        Input:\n        B = matrix with testdata\n        Ws = matrix with 10 dictionaries\n        digits = list of digits in B\n        \n        Output:\n        p = array with what each datapoint has been classified as\n        minID = index for the datapoint of class one with the smallest distance to the basis\n    '''\n    \n    # Make empty list for distances, lists are use in stead of arrays as there were issues writing to the array correctly\n    D = []\n\n    # Write the columnwise distances to the list\n    for i in range(len(Ws)):\n        D.append(columndist(Ws[i],B))\n\n    # Convert list to array so further actions are faster\n    Da = np.array(D)\n\n    # Find which basis each test datapoint is closest to\n    p = np.argmin(Da, axis = 0)\n\n    # The next block of code finds all datapoints classified as ones, then returns the index of the datapoint with the smallest distance\n    ones = []\n    for i in range(len(p)):\n        if p[i] == 1:\n            ones.append(Da[1,i])\n        else:\n            ones.append([10])\n    minDI = np.argmin(ones)\n    return p, minDI\n\n\nmaxiter = 50\ndelta = 10**(-2)\n\ndef predictNN(B, WsNN, digits):\n    '''\n    This function takes in a set of test data, a set of \n    dictionaries for all digits, and a set of which digits are in the test data.\n    ----------------------------------\n        Input:\n        B = matrix with testdata\n        WsNN = matrix with 10 non negative dictionaries\n        digits = list of digits in B\n        \n        Output:\n        p = array with what each datapoint has been classified as\n    '''\n    \n    # Make empty list for distances, lists are use in stead of arrays as there were issues writing to the array correctly\n    D = []\n    \n    # Write the columnwise distances to the list\n    for i in range(len(WsNN)):\n        D.append(nncolumndist(WsNN[i],B, maxiter, delta))\n    \n    # Find which basis each test datapoint is closest to\n    p = np.argmin(D, axis = 0)\n    \n    return p","block_group":"58199cd2a15a4d3d8a96c8430befcc09","execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"4c9ed2ede5c14aba889af43dc2bfe80a","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"3b","block_group":"4c9ed2ede5c14aba889af43dc2bfe80a"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"25e4ae33-d6fe-4e27-b8b7-ab0c8af2c877","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"The accuracy of classification is as simple as finding how many digits were classified correctly, divided by the total number of digits. The recall of each digit, and which digits were misclassified are also of interest. The code below defines a function which returns the accuracy and recall for a given set of predictions and labels. After that two sets of basis vectors are created, and both models are tested for accuracy and recall with three digits, for d = 32, and d = 16.","block_group":"25e4ae33-d6fe-4e27-b8b7-ab0c8af2c877"},{"cell_type":"code","metadata":{"tags":[],"cell_id":"c4541aa3d12044ee824a77180349f2a4","source_hash":"af1e34f9","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"def calcAcc (predict, label, digits):\n    '''\n    This function takes in predictions, labels, and the digits in the testset, and\n    returns the total accuracy, and the recall for each digit\n    ---------------------------------------------------------------------------\n        Input:\n        predict = predicted classes for the datapoints\n        label = true classes for the datapoints\n        digits = list of digits in testset\n        \n        Output:\n        correct/np.size(predict) = total accuracy\n        recall/total = recall for each digit\n        np.array(wrongIndex) = list of index of all misclassified datapoints\n    \n    '''\n    \n    # Initialise all necessary empty lists, arrays, and variables\n    recall = np.zeros(len(digits))\n    correct = 0\n    wrongIndex = []\n    total = np.zeros(len(digits))\n\n    # Iterate through all datapoints and check if it's classified correctly\n    for i in range(len(predict)):\n        if predict[i] == label[i]:\n            correct += 1\n            recall[np.where(digits == predict[i])] += 1\n        else:\n            wrongIndex.append(i)\n        total[np.where(digits == label[i])] += 1\n    return correct/np.size(predict), recall/total, np.array(wrongIndex)\n\n    ","block_group":"c4541aa3d12044ee824a77180349f2a4","execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"59493c30fba043df9ff59ebef9d96009","source_hash":"4fb16167","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"# Create initial values\ndigits = [1,4,5]\nd = 32\nd2 = 16\nn = 1100\n\n# Generate test dataset\nA_test, A_labels = generate_test(test, digits = digits, N = 800)\n\n#Create empty list to store calculations for later use\nAlist = []\nUlist = []\nSlist = []\nVlist = []\n\n# Create dictionaries to use in classification\ndicts = []\ndicts16 = []\ndictsNN = []\ndictsNN16 = []\nfor i in range(10):\n    A = train[:,i,:n]\n\n    U,S,V= np.linalg.svd(A, full_matrices = False)\n\n    #Store results of SVD calculation to avoid calculating them again\n    Alist.append(A)\n    Ulist.append(U)\n    Slist.append(S)\n    Vlist.append(V)\n    \n    L, H = truncSVD(U,S,V,d)\n    L16, H = truncSVD(U,S,V,d16)\n    dicts.append(L)\n    dicts16.append(L16)\n    dictsNN.append(Wnn(A,d))\n    dictsNN16.append(Wnn(A,d16))\n\n\n# Create predictions for SVD and ENMF methods\npredictions, minIndex = predict(A_test, dicts, digits)\npredictionsNN = predictNN(A_test, dictsNN, digits)\npredictions16, minIndex16 = predict(A_test, dicts16, digits)\npredictionsNN16 = predictNN(A_test, dictsNN16, digits)\n\n# Test predictions for SVD and ENMF methods\nacc, recall, wrongIndex = calcAcc(predictions, A_labels, digits)\naccNN, recallNN, wrongIndexNN = calcAcc(predictionsNN, A_labels, digits)\nacc16, recall16, wrongIndex16 = calcAcc(predictions, A_labels, digits)\naccNN16, recallNN16, wrongIndexNN16 = calcAcc(predictionsNN, A_labels, digits)\n\n# Print accuracy and recall\nprint('d = 32')\nprint('Accuracy for the SVD method: ', acc, '\\nAccuracy for the ENMF method: ', accNN)\nprint('SVD Recall for 1,4,5: ', recall, '\\nENMF Recall for 1,4,5: ', recallNN)\nprint('d = 16')\nprint('Accuracy for the SVD method: ', acc16, '\\nAccuracy for the ENMF method: ', accNN16)\nprint('SVD Recall for 1,4,5: ', recall16, '\\nENMF Recall for 1,4,5: ', recallNN16)\n","block_group":"59493c30fba043df9ff59ebef9d96009","execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"6e240537bfe94abda39167a1dad8d3bb","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"It's clear that the SVD method is significantly better, as shown by the accuracy statistics. One can also note that the accuracy for specific numbers are different. Both the methods have very high accuracy for images of ones, and notably worse accuracy for four, and even worse for five. This can be attributed to the complexity of the numbers, and how differently the numbers can be written. ","block_group":"6e240537bfe94abda39167a1dad8d3bb"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"2e99ede4-8891-4046-9136-699f280acf95","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"The SVD method is better as it's generally better at representing data that fits with the basis vectors. While the ENMF method is a lot faster, it has a payoff of not being as accurate. It is also more dependent on having more basis vectors. This was shown when the test was ran with d = 16. In this case the SVD method was approximately as accurate as with d = 32. However, the ENMF method only had an accuracy of 82% with d = 16. This phenomenon will be explored more thoroughly in exercise 3f), but a short explanation is that as the ENMF method picks basis vectors at random, so it needs more vectors to be able to consistently represent data well. Whereas the SVD method creates and uses the d most important vectors for its basis.","block_group":"2e99ede4-8891-4046-9136-699f280acf95"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"87522b31086e4d6a8322b9f7ee077aaa","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"3c","block_group":"87522b31086e4d6a8322b9f7ee077aaa"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"0b995330-b314-4908-82c8-99d51ea1fccc","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"This code shows the most likely one, as found with the predict() function, and then its projection onto the SVD basis for ones.","block_group":"0b995330-b314-4908-82c8-99d51ea1fccc"},{"cell_type":"code","metadata":{"tags":[],"cell_id":"89c5dc0976b74affa2201c5083ab301c","source_hash":"891da128","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"# Plot the one that has the smallest distance to the basis for ones\nplt.imshow(A_test[:, minIndex].reshape((28,28)), cmap = 'gray')\nplt.title('Most likely One')\nplt.axis('off')\nplt.show()\nproj = orthproj(dicts[1], A_test[:, minIndex])\nplt.imshow(proj.reshape((28,28)), cmap = 'gray')\nplt.title('Projection of most likely One')\nplt.axis('off')\nplt.show()","block_group":"89c5dc0976b74affa2201c5083ab301c","execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"0801d98b8573403ab77c0e5170a85b7c","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"The projection looks very similar to the original image, but with some small artifacts in the background, and a general smoothing of the image.","block_group":"0801d98b8573403ab77c0e5170a85b7c"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"c01ca732-cd6b-4b5f-85d6-5c67bfa95c1e","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"3d","block_group":"c01ca732-cd6b-4b5f-85d6-5c67bfa95c1e"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"e954b937-f0fe-4388-bddd-b7b2944ad419","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"This code finds a misclassified one, by going through the list of misclassified digits generated by predict(), and finds the first digit that is a one. This one is then plotted.","block_group":"e954b937-f0fe-4388-bddd-b7b2944ad419"},{"cell_type":"code","metadata":{"tags":[],"cell_id":"1cdfa93a94604839b39b2ef4a387000f","source_hash":"77de3ca2","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"# Index of the first misclassified one\nwrongOfClass = wrongIndex[0]\ni = 0\n\n# Find a misclassified number of the right class, in this case a one\nwhile A_labels[wrongOfClass] != 1:\n    wrongOfClass = wrongIndex[i]\n    i+=1\nplt.imshow(A_test[:, wrongOfClass].reshape((28,28)), cmap = 'gray')\nplt.title('Misclassified One')\nplt.axis('off')\nplt.show()","block_group":"1cdfa93a94604839b39b2ef4a387000f","execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"175b9812ae3a4018ad3a4a31e8bcd7b0","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"There were two main types of misclassified ones. For the first type the main difference is that the one is drawn with an exaggerated horizontal line on the top and bottom. This leads the algorithm to no longer recognise it as a one, as it doesn't fit with the standart vertical line model. The other type is simply too skewed or bent to be recognised as a one.","block_group":"175b9812ae3a4018ad3a4a31e8bcd7b0"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"0f11dda4-19c5-4263-a89e-3be16b6dde45","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"3e","block_group":"0f11dda4-19c5-4263-a89e-3be16b6dde45"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"7fd0ff17-b8d3-43fe-afbf-eea10c2331e6","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"The next piece of code classifies a set of data with an extra digit to see if the results noticably change.","block_group":"7fd0ff17-b8d3-43fe-afbf-eea10c2331e6"},{"cell_type":"code","metadata":{"tags":[],"cell_id":"3a184a453e914355a9a211979fea26cf","source_hash":"8e910712","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"# Add 8 to the list of digits\ndigits_e = [1,4,5,8]\nd = 32\n\n# Create new test data\nA_test_e, A_labels_e = generate_test(test, digits = digits_e, N = 800)\n\n# As we test with all digits as possibilities there is no need to train the model again\npredictions_e, minIndex_e = predict(A_test_e, dicts, digits_e)\nacc_e, recall_e, wrongIndex_e = calcAcc(predictions_e, A_labels_e, digits_e)\n\nprint(acc_e, recall_e)\n","block_group":"3a184a453e914355a9a211979fea26cf","execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"b2153e4e98bc4798948ceabbe0fc5bed","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"One can notice that the total accuracy has gone down a little bit, but that the recall of the digits we had before is consistent. This makes sense as there is no change to the dictionaries, only that new images get categorised. The reason the total accuracy goes down is that the new digit has a recall that's lower than the average accuracy.","block_group":"b2153e4e98bc4798948ceabbe0fc5bed"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"910e48a4-4d18-4890-9132-980e96cc72eb","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"3f","block_group":"910e48a4-4d18-4890-9132-980e96cc72eb"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"67ffdc89-3a72-4fca-a877-5494bb2e6dd0","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"There are many variables that can influence the accuracy of the models, but one significant one is the value of d, or how many basis vectors there are. It's important to choose the correct value for d, and to find the best value one can plot accuracy as a function of d. The code underneath calculates the accuracy of the SVD and ENMF method for different values of d, and then plots them. ","block_group":"67ffdc89-3a72-4fca-a877-5494bb2e6dd0"},{"cell_type":"code","metadata":{"tags":[],"cell_id":"cc93beb5220f4ec683920d72dfc8c921","source_hash":"13e24113","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"# Create array with values of d\nD = np.zeros(11)\nfor i in range(11):\n    D[i] = 2**i\n\n# Define which digits we will test for, and generate test data\ndigits_f = [1,4,5]\nA_test, A_labels_f = generate_test(test, digits = digits_f, N = 800)\n\n\n# Make empty arrays for accuracies\nacc = np.zeros(11)\naccNN = np.zeros(11)\n\n# Iterate through values in D\nfor i in range(11):\n    # Create empty list for a set of dictionaries\n    dicts_f = []\n    dictsNN_f = []\n    # Iterate through all digits\n    for j in range(10):\n        # Use previously calculated SVD results\n        A = Alist[j]\n        U = Ulist[j]\n        S = Slist[j]\n        V = Vlist[j]\n            \n        di = int(D[i])\n        \n        # Create dictionaries with specific values of d\n        L, H = truncSVD(U,S,V,di)\n        dicts_f.append(L)\n        dictsNN_f.append(Wnn(A,di))\n    \n    # Calculate accuracies\n    pred, waste = predict(A_test, dicts_f, digits_f)\n    predNN = predictNN(A_test, dictsNN_f, digits_f)\n    acc[i], waste , waste1 = calcAcc(pred, A_labels_f, digits_f)\n    accNN[i], waste, waste1 = calcAcc(predNN, A_labels_f, digits_f)","block_group":"cc93beb5220f4ec683920d72dfc8c921","execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"c05b82708fcb4baba54a0fe56f92f5d6","source_hash":"5143305b","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"# Plot accuracy vs i, where d = 2^i\nI = [0,1,2,3,4,5,6,7,8,9,10]\nplt.plot(I,acc)\nplt.title('Accuracy vs d : SVD method')\nplt.xlabel('i : d = $2^i$')\nplt.ylabel('accuracy')\nplt.show()\nplt.plot(I,accNN)\nplt.title('Accuracy vs d : ENMF method')\nplt.xlabel('i : d = $2^i$')\nplt.ylabel('accuracy')\nplt.show()","block_group":"c05b82708fcb4baba54a0fe56f92f5d6","execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"6097c99b52ca4a0bbe88593bc99a02ac","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"Here we see that the accuracy for the SVD method rises and peaks as d is between 16 and 32, and then falls off as d increases past that. This makes sense, as with too high values of d, the SVD method will eventually be able to reproduce a much wider range of images than what it is intended for. ","block_group":"6097c99b52ca4a0bbe88593bc99a02ac"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"152b9514-2c35-4c10-ba79-38c826d0fb1a","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"As d rises further past 512, the accuracy rises again. This doesn't seem to make sense, but one possible explanation is that for very high values of d, the distance to all the basises is very close to zero, but that because of numerical approximation errors, the correct basis has a slightly smaller distance.","block_group":"152b9514-2c35-4c10-ba79-38c826d0fb1a"},{"cell_type":"markdown","metadata":{"tags":[],"is_collapsed":false,"formattedRanges":[],"cell_id":"a38634a3-fd7e-4107-b47e-fb3494e52704","deepnote_cell_type":"text-cell-p"},"source":"The ENMF method on the other hand only gets better as d increases. This is because the ENMF method uses randomly selected vectors as its basis, and attempts to represent the data points as a linear combination of the basis vectors. It then makes sense that with more vectors of a certain class, the method becomes better at reconizing data points in that class.","block_group":"a38634a3-fd7e-4107-b47e-fb3494e52704"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"7f393567c191402cafce05b5b1e9886a","is_collapsed":false,"formattedRanges":[{"type":"marks","marks":{"bold":true},"toCodePoint":23,"fromCodePoint":0}],"deepnote_cell_type":"text-cell-p"},"source":"Conclusion and summary:","block_group":"7f393567c191402cafce05b5b1e9886a"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"bd66735a-c512-4401-8120-e242a0cefbde","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"First we found a way to represent a matrix as a matrix product, using singular value decomposition, and ENMF method. In order to represent matrices more efficiently they were represented with truncated matrices.  In task two the relationship between how well an image was represented, and how many basis vectors were used was explored, and it was found that more basis vectors led to a more accurate representation, and smaller distances between images and projections. The ENMF method was discovered to be good at visually representing images, due to them being inherently non-negative. In general the ENMF method had larger distances, most likely due to numerical errors in the projection method. Dictionaries constructed using both methods, showed poor ability to represent images which they were not trained.  In task 3 the method was used to classify new data, and tested to see how accurate it was. It was found that certain digits were more accurately classified, and that differing values of d had different effects on the accuracy for each model. As d increased the SVD model improved up to a point, then got substantially worse, then got better as d increased more. In conclusion we managed to classify digits from the MNIST dataset using dictionary learning.  ","block_group":"bd66735a-c512-4401-8120-e242a0cefbde"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"f31a8c5f-0b3c-46e1-8beb-2689a8fa1194","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"","block_group":"f31a8c5f-0b3c-46e1-8beb-2689a8fa1194"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"6f04c4e3-6fdb-4d1e-8db6-8e59bab3531e","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"","block_group":"6f04c4e3-6fdb-4d1e-8db6-8e59bab3531e"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"f8ed9d6c-6e4e-472a-909d-3d8b00722453","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"},"source":"Below is code that that generates a test set.","block_group":"f8ed9d6c-6e4e-472a-909d-3d8b00722453"},{"cell_type":"code","metadata":{"tags":[],"cell_id":"52ee6d5b58e241f486c83acfe1670cdc","deepnote_cell_type":"code"},"source":"def generate_test(test, digits = [0,1,2], N = 800):\n    \"\"\"\n    Randomly generates test set.\n    input:\n        test: numpy array. Should be the test data loaded from file\n        digits: python list. Contains desired integers\n        N: int. Amount of test data for each class\n    output:\n        test_sub: (784,len(digits)*N) numpy array. Contains len(digits)*N images\n        test_labels: (len(digits)*N) numpy array. Contains labels corresponding to the images of test_sub\n    \"\"\"\n\n    assert N <= test.shape[2] , \"N needs to be smaller than or equal to the total amount of available test data for each class\"\n\n    assert len(digits)<= 10, \"List of digits can only contain up to 10 digits\"\n\n    # Arrays to store test set and labels\n    test_sub = np.zeros((test.shape[0], len(digits)*N))\n    test_labels = np.zeros(len(digits)*N)\n\n    # Iterate over all digit classes and store test data and labels\n    for i, digit in enumerate(digits):\n        test_sub[:, i*N:(i+1)*N] = test[:,digit,:]\n        test_labels[i*N:(i+1)*N] = digit\n\n    # Indexes to be shuffled \n    ids = np.arange(0,len(digits)*N)\n\n    # Shuffle indexes\n    np.random.shuffle(ids)\n\n    # Return shuffled data \n    return test_sub[:,ids], test_labels[ids]","block_group":"52ee6d5b58e241f486c83acfe1670cdc","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"3deea3e2-f474-49e4-a187-9d2829a0ec3d","is_collapsed":false,"formattedRanges":[{"type":"marks","marks":{"bold":true},"toCodePoint":8,"fromCodePoint":0}],"deepnote_cell_type":"text-cell-p"},"source":"Sources:","block_group":"3deea3e2-f474-49e4-a187-9d2829a0ec3d"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"0c7a485864f64f83bdf9104823568e8d","is_collapsed":false,"formattedRanges":[{"type":"marks","marks":{"italic":true},"toCodePoint":123,"fromCodePoint":23}],"deepnote_cell_type":"text-cell-p"},"source":"•\tLudvigsen, M.(2023). TMA4320 vår 2023 - Industriell Matematikk-Prosjekt : Dictionary learning for classification problems. https://wiki.math.ntnu.no/_media/tma4320/2023v/tma4320_indmat_prosjekt_2023_3_.pdf ","block_group":"0c7a485864f64f83bdf9104823568e8d"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"0dd4a3fa-87a8-46a3-a874-b7641278e3bf","is_collapsed":false,"formattedRanges":[{"type":"marks","marks":{"italic":true},"toCodePoint":70,"fromCodePoint":20}],"deepnote_cell_type":"text-cell-p"},"source":"•\tMenke, W. (2012). Geophysical Data Analysis: Discrete Inverse Theory(3). s. 127. https://reader.elsevier.com/reader/sd/pii/B9780123877772000100?token=7E541E7491E530C06567DB7648A98E55C4974918680E56547276845959C392C8726E5265408FDE8F0133C72C024639E9&originRegion=eu-west-1&originCreation=20230301103941 ","block_group":"0dd4a3fa-87a8-46a3-a874-b7641278e3bf"},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=a8f472f0-629c-48c0-8abb-c141867b9bd2' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_notebook_id":"fe5ae1397c814f0f9649f1c3f1372e4d","deepnote_persisted_session":{"createdAt":"2023-03-04T22:30:11.655Z"},"deepnote_execution_queue":[]}}